{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FQXM42BLnCz"
   },
   "source": [
    "# **Learn OpenCV for Computer Vision**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRMkSSIrVt9W"
   },
   "source": [
    "### **What is OpenCV?**\n",
    "OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products.\n",
    "\n",
    "> The library has **more than 2500** optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms.\n",
    "\n",
    "### **OpenCV Implementation**\n",
    "bla bla bla ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "879mmxgoNUFA"
   },
   "source": [
    "## **Table of Contents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu_W4CA6OQ1u"
   },
   "source": [
    "1. Image and Video in Computer Vision\n",
    "2. Basic Function OpenCV\n",
    "3. Edge Detection\n",
    "4. Shapes and Text\n",
    "5. Warp Perspective\n",
    "6. Joining Images\n",
    "7. Color Detection\n",
    "8. Contour / Shape Detection\n",
    "9. Implementasi Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSfESgU9T6GX"
   },
   "source": [
    "## **Image and Video in Computer Vision**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKee_Gr1UH3m"
   },
   "source": [
    "### **What is Image?**\n",
    "Image adalah ...\n",
    "\n",
    "</br>\n",
    "\n",
    "Video adalah ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdP_A6ZMp2Dy"
   },
   "source": [
    "## **Basic Function OpenCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMUWq9BCqDt2"
   },
   "source": [
    "### Import OpenCV Libary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Yn6Tv7qqLWG"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StfE42lNqV6Q"
   },
   "source": [
    "### Read Input from Image, Video, and WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "cVfBDIypqfD_",
    "outputId": "66d8e74e-d65e-4039-b1a4-8b92ceac2289"
   },
   "outputs": [],
   "source": [
    "# Read from Image\n",
    "img = cv2.imread(\"cat.jpg\")\n",
    "\n",
    "cv2.imshow(\"Wilson the Cat\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "-jnFRVwHrmq_",
    "outputId": "6d8069b7-5a07-4c7a-e808-60105b418b3d"
   },
   "outputs": [],
   "source": [
    "# Read from Video\n",
    "frameWidth = 480\n",
    "frameHeight = 640\n",
    "cap = cv2.VideoCapture(\"cat-video.mp4\")\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    img = cv2.resize(img, (frameWidth, frameHeight))\n",
    "    cv2.imshow(\"Result\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from Webcam\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(0) # change 0 to your webcam index\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, frameWidth)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frameHeight)\n",
    "cap.set(10, 150)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cv2.imshow(\"WebCam\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Setting Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "0. CV_CAP_PROP_POS_MSEC        : Current position of the video file in milliseconds.\n",
    "1. CV_CAP_PROP_POS_FRAMES      : 0-based index of the frame to be decoded/captured next.\n",
    "2. CV_CAP_PROP_POS_AVI_RATIO   : Relative position of the video file\n",
    "3. CV_CAP_PROP_FRAME_WIDTH     : Width of the frames in the video stream.\n",
    "4. CV_CAP_PROP_FRAME_HEIGHT    : Height of the frames in the video stream.\n",
    "5. CV_CAP_PROP_FPS             : Frame rate.\n",
    "6. CV_CAP_PROP_FOURCC          : 4-character code of codec.\n",
    "7. CV_CAP_PROP_FRAME_COUNT     : Number of frames in the video file.\n",
    "8. CV_CAP_PROP_FORMAT          : Format of the Mat objects returned by retrieve() .\n",
    "9. CV_CAP_PROP_MODE            : Backend-specific value indicating the current capture mode.\n",
    "10. CV_CAP_PROP_BRIGHTNESS     : Brightness of the image (only for cameras).\n",
    "11. CV_CAP_PROP_CONTRAST       : Contrast of the image (only for cameras).\n",
    "12. CV_CAP_PROP_SATURATION     : Saturation of the image (only for cameras).\n",
    "13. CV_CAP_PROP_HUE            : Hue of the image (only for cameras).\n",
    "14. CV_CAP_PROP_GAIN           : Gain of the image (only for cameras).\n",
    "15. CV_CAP_PROP_EXPOSURE       : Exposure (only for cameras).\n",
    "16. CV_CAP_PROP_CONVERT_RGB    : Boolean flags indicating whether images should be converted to RGB.\n",
    "17. CV_CAP_PROP_WHITE_BALANCE  : Currently unsupported\n",
    "18. CV_CAP_PROP_RECTIFICATION  : Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"cat.jpg\")\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "\n",
    "# Resize Image\n",
    "resizedImage = cv2.resize(img, (640, 480))\n",
    "cv2.imshow(\"Resized Image\", resizedImage)\n",
    "\n",
    "# Rotate Image\n",
    "rotatedImage = cv2.rotate(resizedImage, cv2.ROTATE_90_CLOCKWISE)\n",
    "cv2.imshow(\"Rotated Image\", rotatedImage)\n",
    "\n",
    "# Flip Image\n",
    "flippedImage = cv2.flip(resizedImage, 1)\n",
    "cv2.imshow(\"Flipped Image\", resizedImage)\n",
    "\n",
    "# Crop Image\n",
    "croppedImage = resizedImage[50:200, 200:400]\n",
    "cv2.imshow(\"Cropped Image\", croppedImage)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color and Filter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"cat.jpg\")\n",
    "img = cv2.resize(img, (640,480))\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(img, (9,9), 0)\n",
    "imgMedian = cv2.medianBlur(img, 9)\n",
    "\n",
    "cv2.imshow(\"Gray Image\", imgGray)\n",
    "cv2.imshow(\"Blur Image\", imgBlur)\n",
    "cv2.imshow(\"Median Image\", imgMedian)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Image and Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Image\n",
    "img = cv2.imread(\"cat.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite(\"saved_image.jpg\", img)\n",
    "\n",
    "print(\"Successfully saved image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Video\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(0) # change 0 to your webcam index\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, frameWidth)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frameHeight)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\"output.mp4\", fourcc, 20.0, (frameWidth, frameHeight))\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    out.write(img)\n",
    "    cv2.imshow(\"WebCam\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Saved Video\n",
    "cap = cv2.VideoCapture(\"output.mp4\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000 / fps)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cv2.imshow(\"Result\", img)\n",
    "    if cv2.waitKey(delay) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Edge Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"ganci.jpg\")\n",
    "\n",
    "img = cv2.resize(img, (480, 640))\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "imgCanny = cv2.Canny(img, 150, 200)\n",
    "imgDialation = cv2.dilate(imgCanny, kernel, iterations=1)\n",
    "imgEroded = cv2.erode(imgDialation, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow(\"Canny Image\", imgCanny)\n",
    "cv2.imshow(\"Dialation Image\", imgDialation)\n",
    "cv2.imshow(\"Eroded Image\", imgEroded)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Shapes and Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plainImage = np.zeros((512, 512, 3), np.uint8)\n",
    "blue = (255, 0, 0)\n",
    "green = (0, 255, 0)\n",
    "red = (0, 0, 255)\n",
    "white = (255, 255, 255)\n",
    "\n",
    "cv2.line(plainImage, (50, 0), (50, 512), red, 3)\n",
    "cv2.rectangle(plainImage, (100, 100), (250, 350), green, 3)\n",
    "cv2.circle(plainImage, (400, 400), 30, blue, cv2.FILLED)\n",
    "cv2.putText(plainImage, \"ICHIRO ITS\", (300, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, white, 3)\n",
    "\n",
    "cv2.imshow(\"Image\", plainImage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Warp Perspective**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def print_coordinates(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(f\"[{x}, {y}],\")\n",
    "        cv2.circle(img, (x, y), 5, (255, 0, 0), -1)\n",
    "        cv2.imshow(\"Image\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"ganci-2.jpg\")\n",
    "cv2.imshow(\"Image\", img)\n",
    "\n",
    "cv2.setMouseCallback(\"Image\", print_coordinates)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"ganci-2.jpg\")\n",
    "\n",
    "width, height = 250, 650\n",
    "coordinates = [\n",
    "  [98, 198],\n",
    "  [183, 168],\n",
    "  [234, 452],\n",
    "  [341, 391],\n",
    "]\n",
    "\n",
    "pts1 = np.float32(coordinates)\n",
    "pts2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "imgOutput = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Output\", imgOutput)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Joining Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def joinImages(scale, imgArray):\n",
    "    for i in range(0, len(imgArray)):\n",
    "        if imgArray[i].shape[:2] == imgArray[0].shape[:2]:\n",
    "            imgArray[i] = cv2.resize(imgArray[i], (0, 0), None, scale, scale)\n",
    "        else:\n",
    "            imgArray[i] = cv2.resize(imgArray[i], (imgArray[0].shape[1], imgArray[0].shape[0]), None, scale, scale)\n",
    "        if len(imgArray[i].shape) == 2: imgArray[i] = cv2.cvtColor(imgArray[i], cv2.COLOR_GRAY2BGR)\n",
    "    hor= np.hstack(imgArray)\n",
    "    ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('rubik.jpg')\n",
    "imgFliped0 = cv2.flip(img, 0)\n",
    "imgFliped1 = cv2.flip(img, 1)\n",
    "imgFliped2 = cv2.flip(img, -1)\n",
    "\n",
    "imgStack = joinImages(0.5, ([img, imgFliped0, imgFliped1, imgFliped2]))\n",
    "cv2.imshow(\"ImageStack\", imgStack)\n",
    "\n",
    "# Using Numpy\n",
    "# imgHor = np.hstack((imgFliped0, imgFliped1))\n",
    "# imgVer = np.vstack((imgFliped0, imgFliped1))\n",
    "\n",
    "# imgHor = cv2.resize(imgHor, (0, 0), None, 0.5, 0.5)\n",
    "# imgVer = cv2.resize(imgVer, (0, 0), None, 0.5, 0.5)\n",
    "\n",
    "# cv2.imshow(\"Horizontal\", imgHor)\n",
    "# cv2.imshow(\"Vertical\", imgVer)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Color Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Color Settings\")\n",
    "cv2.resizeWindow(\"Color Settings\", 640, 240)\n",
    "cv2.createTrackbar(\"Hue Min\", \"Color Settings\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Hue Max\", \"Color Settings\", 255, 255, empty)\n",
    "cv2.createTrackbar(\"Sat Min\", \"Color Settings\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Sat Max\", \"Color Settings\", 255, 255, empty)\n",
    "cv2.createTrackbar(\"Val Min\", \"Color Settings\", 0, 255, empty)\n",
    "cv2.createTrackbar(\"Val Max\", \"Color Settings\", 255, 255, empty)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cap.set(cv2.CAP_PROP_SATURATION, 60)\n",
    "\n",
    "while True:\n",
    "    # img = cv2.imread(\"rubik.jpg\")\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\", \"Color Settings\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"Color Settings\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"Color Settings\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"Color Settings\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"Color Settings\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"Color Settings\")\n",
    "\n",
    "    print(f\"\\r[{h_min}, {h_max}, {s_min}, {s_max}, {v_min}, {v_max}]\", end=\"\\r\")\n",
    "\n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "    imgResult = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    imgStack = joinImages(0.6, [img, imgHSV, mask, imgResult])\n",
    "    cv2.imshow(\"Images\", imgStack)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PROJECT IMPLEMENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Code Together"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
